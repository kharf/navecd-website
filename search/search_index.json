{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#embrace-gitops","title":"Embrace GitOps","text":"<ul> <li> <p>Declarative</p> <p>Navecd integrates CUE natively - A type safe configuration language with the benefits of general-purpose programming languages</p> </li> <li> <p>Versioned and Immutable</p> <p>OCI repositories as the source of truth for defining the desired system state</p> </li> <li> <p>Pulled Automatically</p> <p>Navecd automatically pulls the desired state declarations, written as CUE values, from OCI repositories</p> </li> <li> <p>Continuously Reconciled</p> <p>Navecd is a Kubernetes Controller, which continuously observes actual system state and applies the desired state</p> </li> </ul>"},{"location":"#deploy-anything","title":"Deploy anything","text":"<ul> <li> <p>Kubernetes Manifests</p> <p>Deployments, StatefulSets, Pods, ConfigMaps, ..., anything you can deploy to Kubernetes can be deployed with Navecd.</p> <p>Get started!</p> </li> <li> <p>Helm</p> <p>Got a Helm Chart? Deploy it with Navecd.</p> <p>See how!</p> </li> </ul>"},{"location":"documentation/overview/","title":"Overview","text":""},{"location":"documentation/overview/#what-is-gitops","title":"What is GitOps?","text":"<p>GitOps is a way of implementing Continuous Deployment for cloud native applications by having a repository that contains declarative descriptions of the desired infrastructure and applications and an automated process to reconcile the production environment with the desired state in the repository.</p>"},{"location":"documentation/overview/#why-navecd","title":"Why Navecd?","text":"<p>Traditional GitOps tools often rely on YAML for configuration, which can lead to verbosity and complexity. Navecd leverages CUE, a type safe configuration language with a more concise and expressive syntax and the benefits of general-purpose programming languages, making it easier to define and maintain your desired cluster state.</p> <p>Navecd adheres to the GitOps Principles:</p> <ul> <li> <p>Declarative</p> <p>Navecd integrates CUE natively - A type safe configuration language with the benefits of general-purpose programming languages</p> </li> <li> <p>Versioned and Immutable</p> <p>OCI repositories as the source of truth for defining the desired system state</p> </li> <li> <p>Pulled Automatically</p> <p>Navecd automatically pulls the desired state declarations, written as CUE values, from OCI repositories</p> </li> <li> <p>Continuously Reconciled</p> <p>Navecd is a Kubernetes Controller, which continuously observes actual system state and applies the desired state</p> </li> </ul>"},{"location":"documentation/overview/#deploy-anything","title":"Deploy anything","text":"<p>Deployments, StatefulSets, Pods, ConfigMaps, ..., anything you can deploy to Kubernetes can be deployed with Navecd. Got a Helm Chart? Deploy it with Navecd.</p>"},{"location":"documentation/overview/#basics-of-navecd","title":"Basics of Navecd","text":"<p>Navecd does not enforce any kind of repository structure, but there is one constraint for declarations of cluster state. Every top-level CUE value in a package, which is not hidden and not a Definition, has to be what Navecd calls a Component. Navecd Components effectively describe the desired cluster state and currently exist in two forms: Manifests and HelmReleases. A Manifest is a typical Kubernetes Object, which you would normally describe in yaml format. A HelmRelease is an instance of a Helm Chart. All Components share the attribute to specify Dependencies to other Components. This helps Navecd to identify the correct order in which to apply all objects onto a Kubernetes cluster. See schema.</p>"},{"location":"documentation/overview/#next-steps","title":"Next Steps","text":"<p>Get started with Navecd.</p>"},{"location":"documentation/features/conflicts/","title":"Conflict Management","text":"<p>Navecd uses Server-Side Apply to maintain cluster states and SSA provides a mechanism to track changes to a manifest's fields, which is called <code>Field Management</code>. Navecd takes Ownership of all manifest's fields declared in Git. This makes Navecd a <code>Field Manager</code>.</p> <p>Any change to Navecd managed fields will be overwritten by Navecd and if you commit to using GitOps as your way to deploy to Kubernetes, then manual changes to your cluster are an anti pattern. But there are cases where Field Managers in your cluster try to take over management of certain fields. The most prominent situation probably is a Horizontal Pod Autoscaler mutating the replicas count. In order to avoid fighting over conflicting fields, you can tell Navecd to ignore them, so that the competing manager can take over. </p> myapp/deployment.cue<pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\ndeployment: component.#Manifest &amp; {\n  content: {\n    apiVersion: \"apps/v1\"\n    kind:       \"Deployment\"\n    metadata: {\n      name:      \"my-deployment\"\n      namespace: ns.content.metadata.name\n      labels:    _primaryLabels\n    }\n    spec: {\n      selector: matchLabels: _primaryLabels\n      replicas: 1 @ignore(conflict)\n  ...\n    }\n  }\n}\n</code></pre> <p><code>@ignore(conflicts)</code> is a custom CUE build attribute, implemented and understood by Navecd. You can attach it to fields or declarations to resolve field conflicts.</p>"},{"location":"documentation/features/ha/","title":"High Availability","text":"<p>Sharding is used to distribute workload by installing multiple Navecd Controllers and Navecd uses Leases to make sure that there is only one running Controller per Shard.</p> <p>While that works for most cases, sometimes it is desired to have backup instances running on different nodes to reduce downtime in case of node failures. You can use Pod Anti-Affinity and increase the replica count of your Navecd Controllers to counter that situation:</p> navecd/primary_system.cue<pre><code>package navecd\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nprimaryProjectControllerDeployment: component.#Manifest &amp; {\n  ...\n  content: {\n    apiVersion: \"apps/v1\"\n    kind:       \"Deployment\"\n    metadata: {\n      name:      \"project-controller-primary\"\n      namespace: ns.content.metadata.name\n      labels:    _primaryLabels\n    }\n    spec: {\n      selector: matchLabels: _primaryLabels\n      replicas: 2\n  ...\n    }\n  }\n}\n</code></pre> navecd/ha.cue<pre><code>package navecd\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nprimaryProjectControllerDeployment: component.#Manifest &amp; {\n  content: spec: template: spec: affinity: podAntiAffinity: {\n    requiredDuringSchedulingIgnoredDuringExecution: [{\n      labelSelector: matchExpressions: [{\n        key:      _shardKey\n        operator: \"In\"\n        values: [\"primary\"]\n      }]\n      topologyKey: \"kubernetes.io/hostname\"\n    }]\n  }\n}\n</code></pre>"},{"location":"documentation/features/helm/","title":"Helm","text":"<p>Navecd has first class support for Helm. It can install and upgrade Charts. Drift detection is enabled by default and implemented by patching Helm with Server-Side Apply (SSA).</p>"},{"location":"documentation/features/helm/#install-helm-chart","title":"Install Helm Chart","text":"<p>To install a Helm Chart, declare a desired HelmRelease Component:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nmyRelease: component.#HelmRelease &amp; {\n    name:      \"my-release\"\n    namespace: ns.content.metadata.name\n    chart: {\n        name:    \"my-chart\"\n        repoURL: \"oci://my-chart-repository\"\n        version: \"x.x.x\"\n    }\n    values: {\n      foo: \"bar\"\n    }\n}\n</code></pre>"},{"location":"documentation/features/helm/#private-repositories","title":"Private Repositories","text":"<p>Private Repositories are supported either through Workload Identity or Kubernetes Secrets.</p> <p>A Secret can be referenced as follows:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nmyRelease: component.#HelmRelease &amp; {\n    name:      \"my-release\"\n    namespace: ns.content.metadata.name\n    chart: {\n        name:    \"my-chart\"\n        repoURL: \"oci://my-chart-repository\"\n        version: \"x.x.x\"\n        auth: secretRef: {\n          name: \"secret-name\"\n          // Can not be cross namespace. Field wil be deleted in upcoming versions.\n          namespace: \"secret-namespace\"\n        }\n    }\n    values: {\n      foo: \"bar\"\n    }\n}\n</code></pre>"},{"location":"documentation/features/helm/#custom-resource-definitions-crds","title":"Custom Resource Definitions (CRDs)","text":"<p>Helm 3 supports installation of CRDs through a <code>crds</code> directory inside a Chart, but it does not support upgrades/deletions. See reason.</p> <p>However, CRD upgrade is supported by Navecd and can be enabled:</p> <p>Info</p> <p>Navecd never deletes CRDs contained in a Chart. It only handles installations and upgrades.</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nmyRelease: component.#HelmRelease &amp; {\n    name:      \"my-release\"\n    namespace: ns.content.metadata.name\n\n    chart: {\n        name:    \"my-chart\"\n        repoURL: \"oci://my-chart-repository\"\n        version: \"x.x.x\"\n    }\n\n    crds: allowUpgrade: true\n\n    values: {\n      foo: \"bar\"\n    }\n}\n</code></pre>"},{"location":"documentation/features/helm/#patches-post-rendering","title":"Patches / Post Rendering","text":"<p>Patches allow to manipulate rendered manifests before they are installed or upgraded.  Manifests are identified by their GVK(Group/Version/Kind), Name and Namespace for namespaced manifests.</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nmyRelease: component.#HelmRelease &amp; {\n    name:      \"my-release\"\n    namespace: ns.content.metadata.name\n\n    chart: {\n        name:    \"my-chart\"\n        repoURL: \"oci://my-chart-repository\"\n        version: \"x.x.x\"\n    }\n\n    crds: allowUpgrade: true\n\n    values: {\n      foo: \"bar\"\n    }\n\n    patches: [\n      #deployment &amp; {\n        apiVersion: \"apps/v1\"\n        kind: \"Deployment\"\n        metadata: {\n          name:      \"deployment-from-chart\"\n          namespace: ns.content.metadata.name\n        }\n        spec: {\n          replicas: 2 @ignore(conflict)\n        }\n      },\n    ]\n}\n</code></pre> <p>Noticed the <code>@ignore(conflict)</code> build attribute at line 32? Patches can also be used to \"flag\" manifest fields of Helm Chart templates.</p> <p>Read more here: Conflict Management</p>"},{"location":"documentation/features/multi-tenancy/","title":"Multi-Tenancy / Sharding","text":"<p>The usual GitOps setup consists of a single GitOpsProject and a single GitOps Controller, but Navecd supports Multi-Tenancy, where a system evolves around multiple Git repositories. For example a company wants to split responsibilities to different teams. A platform team could maintain Navecd and all the infrastructure necessary to run a cluster with independant tenants, while each tenant could maintain its own state of applications.</p> <p>Navecd uses the concept of Sharding. Every Navecd Controller instance forms a Shard and GitOpsProjects are assigned to Shards.</p> <p></p>"},{"location":"documentation/features/multi-tenancy/#single-sharded","title":"Single-Sharded","text":"<p>By default Navecd is single-sharded, but multiple GitOpsProjects can be assigned to the same Shard:</p> <p>Info</p> <p>The default Controller Service Account has Cluster Admin rights. You can limit a tenant's permissions by assigning a custom Service Account to the tenant's GitOpsProject. </p> projects.cue<pre><code>package navecd\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nfoundation: component.#Manifest &amp; {\n  dependencies: [\n    crd.id,\n    ns.id,\n  ]\n  content: {\n    apiVersion: \"gitops.navecd.io/v1beta1\"\n    kind:       \"GitOpsProject\"\n    metadata: {\n      name:      \"foundation\"\n      namespace: \"navecd-system\"\n      labels:    {\n        \"navecd/shard\":   \"primary\"\n      }\n    }\n    spec: {\n      branch:              \"main\"\n      pullIntervalSeconds: 30\n      suspend:             false\n      url:                 \"git@github.com:user/platform.git\"\n    }\n  }\n}\n\ntenant: component.#Manifest &amp; {\n  dependencies: [\n    crd.id,\n    ns.id,\n  ]\n  content: {\n    apiVersion: \"gitops.navecd.io/v1beta1\"\n    kind:       \"GitOpsProject\"\n    metadata: {\n      name:      \"tenant\"\n      namespace: \"navecd-system\"\n      labels:    {\n        \"navecd/shard\":   \"primary\"\n      }\n    }\n    spec: {\n      serviceAccountName: \"tenant\"\n      branch:              \"main\"\n      pullIntervalSeconds: 30\n      suspend:             false\n      url:                 \"git@github.com:user/tenant.git\"\n    }\n  }\n}\n</code></pre>"},{"location":"documentation/features/multi-tenancy/#multi-sharded","title":"Multi-Sharded","text":"<p>Info</p> <p>The default shard name is \"primary\" when initializing/installing. You can provide a different one via the \"--shard\" flag.</p> <pre><code># platform shard\nnavecd init github.com/user/mygitops\nnavecd install \\\n  -u git@github.com:user/platform.git \\\n  -b main \\\n  --name dev \\\n  -t &lt;token&gt;\n\n# tenant shard\nnavecd init github.com/user/mygitops --shard tenant --secondary\nnavecd install \\\n  -u git@github.com:user/tenant.git \\\n  -b main \\\n  --name dev \\\n  -t &lt;token&gt; \\\n  --shard tenant\n</code></pre> <p>A complete example can be found here: Navecd Platform Example.</p>"},{"location":"documentation/features/secrets/","title":"Secrets","text":"<p>Secrets, encrypted or unencrypted, should not reside in source repositories and are best managed by a dedicated secret manager.</p> <p>Navecd integrates well with the External Secrets Operator.</p>"},{"location":"documentation/features/secrets/#example","title":"Example","text":"infrastructure/eso.cue<pre><code>package externalsecrets\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\n_name: \"external-secrets\"\n\nns: component.#Manifest &amp; {\n  apiVersion: \"v1\"\n  kind: \"Secret\"\n  metadata: name: _name\n}\n\nrelease: component.#HelmRelease &amp; {\n  dependencies: [\n    ns.id,\n  ]\n  name:      _name\n  namespace: ns.content.metadata.name\n  chart: {\n    name:    _name\n    repoURL: \"oci://ghcr.io/external-secrets/charts\"\n    version: \"x.x.x\"\n  }\n}\n</code></pre> infrastructure/store.cue<pre><code>package externalsecrets\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  // go get github.com/external-secrets/external-secrets/apis/externalsecrets/v1beta1\n  // cue get go github.com/external-secrets/external-secrets/apis/externalsecrets/v1beta1\n  \"github.com/external-secrets/external-secrets/apis/externalsecrets/v1beta1\"\n)\n\nstoreServiceAccount: component.#Manifest &amp; {\n  dependencies: [\n    ns.id,\n  ]\n  content: {\n    apiVersion: \"v1\"\n    kind:       \"ServiceAccount\"\n    metadata: {\n      name:      \"secret-store\"\n      namespace: ns.content.metadata.name\n    }\n  }\n}\n\nstoreRole: component.#Manifest &amp; {\n  content: {\n    apiVersion: \"rbac.authorization.k8s.io/v1\"\n    kind:       \"ClusterRole\"\n    metadata: {\n      name: \"secret-store\"\n    }\n    rules: [{\n      apiGroups: [\"\"]\n      resources: [\"secrets\"]\n      verbs: [\n        \"get\",\n        \"list\",\n        \"watch\",\n      ]\n    }, {\n      apiGroups: [\"authorization.k8s.io\"]\n      resources: [\"selfsubjectrulesreviews\"]\n      verbs: [\"create\"]\n    }]\n  }\n}\n\nstoreRoleBinding: component.#Manifest &amp; {\n  dependencies: [\n    secretsNs.id,\n    storeRole.id,\n    storeServiceAccount.id,\n  ]\n  content: {\n    apiVersion: \"rbac.authorization.k8s.io/v1\"\n    kind:       \"RoleBinding\"\n    metadata: {\n      name:      \"secret-store\"\n      namespace: secretsNs.content.metadata.name\n    }\n    roleRef: {\n      apiGroup: \"rbac.authorization.k8s.io\"\n      kind:     storeRole.content.kind\n      name:     storeRole.content.metadata.name\n    }\n    subjects: [{\n      kind:      storeServiceAccount.content.kind\n      name:      storeServiceAccount.content.metadata.name\n      namespace: storeServiceAccount.content.metadata.namespace\n    }]\n  }\n}\n\nstore: component.#Manifest &amp; {\n  dependencies: [\n    storeServiceAccount.id,\n  ]\n  content: v1beta1.#SecretStore &amp; {\n    apiVersion: \"external-secrets.io/v1beta1\"\n    kind:       \"SecretStore\"\n    metadata: {\n      name:      \"secret-store\"\n      namespace: ns.content.metadata.name\n    }\n    spec: provider: kubernetes: {\n      remoteNamespace: \"secrets\"\n      server: {\n        caProvider: {\n          type: \"ConfigMap\"\n          name: \"kube-root-ca.crt\"\n          key:  \"ca.crt\"\n        }\n      }\n      auth: serviceAccount: name: storeServiceAccount.content.metadata.name\n    }\n  }\n}\n\nsecrets: component.#Manifest &amp; {\n  dependencies: [\n    store.id,\n  ]\n  content: v1beta1.#ExternalSecret &amp; {\n    apiVersion: \"external-secrets.io/v1beta1\"\n    kind:       \"ExternalSecret\"\n    metadata: {\n      name:      \"secrets\"\n      namespace: ns.content.metadata.name\n    }\n    spec: {\n      refreshInterval: \"1h\"\n      secretStoreRef: {\n        kind: \"SecretStore\"\n        name: store.content.metadata.name\n      }\n      target: {\n        name: secretsNs.content.metadata.name\n      }\n      data: [{\n        secretKey: \"username\"\n        remoteRef: {\n          key:      \"database-credentials\"\n          property: \"username\"\n        }\n      }, {\n      secretKey: \"password\"\n      remoteRef: {\n        key:      \"database-credentials\"\n        property: \"password\"\n      }\n      }]\n        }\n    }\n}\n\nsecretsNs: component.#Manifest &amp; {\n  content: {\n    apiVersion: \"v1\"\n    kind: \"Secret\"\n    metadata: name: \"secrets\"\n  } \n}\n</code></pre>"},{"location":"documentation/features/workload-identity/","title":"Workload Identity","text":"<p>Navecd deployed on Azure AKS, AWS EKS or GCP GKE can be configured to use Workload Identity to access the corresponding cloud container registries.</p>"},{"location":"documentation/features/workload-identity/#azure-aks","title":"Azure AKS","text":"<p>Info</p> <p>See Azure Documentation to learn about how to setup Azure Workload Identity.</p> <p>Annotate the Kubernetes Service Account used for your GitOpsProject with the Microsoft Entra application client ID:</p> <p>Note</p> <p>If no Service Account is provided via the GitOpsProject spec, Navecd uses the ServiceAccount from the Controller Deployment.</p> <pre><code>primaryServiceAccount: component.#Manifest &amp; {\n  dependencies: [ns.id]\n  content: {\n    apiVersion: \"v1\"\n    kind:       \"ServiceAccount\"\n    metadata: {\n      name:      \"project-controller-primary\"\n      namespace: ns.content.metadata.name\n      annotations: \"azure.workload.identity/client-id\": \"&lt;client id&gt;\"\n    }\n  }\n}\n</code></pre> <p>Label Navecd pods to use Workload Identity:</p> <p>Note</p> <p>The Navecd Controller Deployment value name contains the shard name when initialized through the Navecd CLI. The default name is \"primaryProjectControllerDeployment\".</p> navecd/patch.cue<pre><code>package navecd\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n)\n\nprimaryProjectControllerDeployment: component.#Manifest &amp; {\n  content: {\n    spec: template: metadata: labels: {\n      \"azure.workload.identity/use\": \"true\"\n    }\n  }\n}\n</code></pre> <p>Update your Helm Release to use Workload Identity:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nrelease: component.#HelmRelease &amp; {\n  dependencies: [ns.id]\n  name:      \"myapp\"\n  namespace: ns.content.metadata.name\n  chart: {\n    name:    \"myapp\"\n    repoURL: \"oci://myfakeregistry.azurecr.io\"\n    version: \"1.0.0\"\n    auth:    workloadidentity.#Azure\n  }\n}\n</code></pre> <p>Update your GitOpsProject to use Workload Identity:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nproject: component.#Manifest &amp; {\n    dependencies: [\n        crd.id,\n        ns.id,\n    ]\n    content: {\n        apiVersion: \"gitops.navecd.io/v1beta1\"\n        kind:       \"GitOpsProject\"\n        metadata: {\n            name:      \"mygitops\"\n            namespace: \"navecd-system\"\n            labels: _primaryLabels\n        }\n        spec: {\n            url:                 \"oci://myfakeregistry.azurecr.io\"\n            ref:                 \"latest\"\n            pullIntervalSeconds: 5\n            suspend:             false\n            auth: workloadidentity.#Azure\n        }\n    }\n}\n</code></pre>"},{"location":"documentation/features/workload-identity/#aws-eks","title":"AWS EKS","text":"<p>Info</p> <p>See AWS Documentation to learn about how to setup EKS Workload Identity (EKS Pod Identities).</p> <p>Update your Helm Release to use Workload Identity:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nrelease: component.#HelmRelease &amp; {\n  dependencies: [ns.id]\n  name:      \"myapp\"\n  namespace: ns.content.metadata.name\n  chart: {\n    name:    \"myapp\"\n    repoURL: \"oci://myfakeregistry.dkr.ecr.eu-north-1.amazonaws.com\"\n    version: \"1.0.0\"\n    auth:    workloadidentity.#AWS\n  }\n}\n</code></pre> <p>Update your GitOpsProject to use Workload Identity:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nproject: component.#Manifest &amp; {\n    dependencies: [\n        crd.id,\n        ns.id,\n    ]\n    content: {\n        apiVersion: \"gitops.navecd.io/v1beta1\"\n        kind:       \"GitOpsProject\"\n        metadata: {\n            name:      \"mygitops\"\n            namespace: \"navecd-system\"\n            labels: _primaryLabels\n        }\n        spec: {\n            url:                 \"oci://myfakeregistry.azurecr.io\"\n            ref:                 \"latest\"\n            pullIntervalSeconds: 5\n            suspend:             false\n            auth: workloadidentity.#AWS\n        }\n    }\n}\n</code></pre>"},{"location":"documentation/features/workload-identity/#gcp-gke","title":"GCP GKE","text":"<p>Info</p> <p>See GCP Documentation to learn about how to setup GKE Workload Identity (IAM principal identifiers).</p> <p>Update your Helm Release to use Workload Identity:</p> <p><pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nrelease: component.#HelmRelease &amp; {\n  dependencies: [ns.id]\n  name:      \"myapp\"\n  namespace: ns.content.metadata.name\n  chart: {\n    name:    \"myapp\"\n    repoURL: \"oci://europe-west4-docker.pkg.dev/myfakeregistry/charts\"\n    version: \"1.0.0\"\n    auth:    workloadidentity.#GCP\n  }\n}\n</code></pre> Update your GitOpsProject to use Workload Identity:</p> <pre><code>package myapp\n\nimport (\n  \"github.com/kharf/navecd/schema/component\"\n  \"github.com/kharf/navecd/schema/workloadidentity\"\n)\n\nproject: component.#Manifest &amp; {\n    dependencies: [\n        crd.id,\n        ns.id,\n    ]\n    content: {\n        apiVersion: \"gitops.navecd.io/v1beta1\"\n        kind:       \"GitOpsProject\"\n        metadata: {\n            name:      \"mygitops\"\n            namespace: \"navecd-system\"\n            labels: _primaryLabels\n        }\n        spec: {\n            url:                 \"oci://myfakeregistry.azurecr.io\"\n            ref:                 \"latest\"\n            pullIntervalSeconds: 5\n            suspend:             false\n            auth: workloadidentity.#GCP\n        }\n    }\n}\n</code></pre>"},{"location":"documentation/getting-started/deploy/","title":"Deploy your first application","text":"<p>Note</p> <p>For the purpose of demonstration this guide uses Kind to create a Kubernetes cluster and an OCI registry. We recommend that beginners follow along with both.</p> Requirements <ul> <li>Navecd</li> <li>Go</li> <li>Kind</li> <li>Docker/Podman</li> </ul>"},{"location":"documentation/getting-started/deploy/#create-kind-cluster","title":"Create Kind Cluster","text":"<p>Set up a local Kubernetes cluster and local OCI registry as documented in https://kind.sigs.k8s.io/docs/user/local-registry/.</p>"},{"location":"documentation/getting-started/deploy/#initialize-a-navecd-gitops-repository","title":"Initialize a Navecd GitOps Repository","text":"<p><pre><code>mkdir mygitops\ncd mygitops\n# init Navecd gitops repository as a CUE module\nexport CUE_REGISTRY=ghcr.io/kharf\nnavecd init github.com/user/mygitops\ngo mod init mygitops\nnavecd verify\n</code></pre> See CUE module reference for valid CUE module paths.</p>"},{"location":"documentation/getting-started/deploy/#install-navecd-onto-your-kubernetes-cluster","title":"Install Navecd onto your Kubernetes Cluster","text":"<pre><code>navecd install \\\n  -u localhost:5001/mygitops \\\n  -r latest \\\n  --name dev\n</code></pre>"},{"location":"documentation/getting-started/deploy/#deploy-a-manifest-and-a-helmrelease","title":"Deploy a Manifest and a HelmRelease","text":"<p>Get Go Kubernetes Structs and import them as CUE schemas.</p> <p>Tip</p> <p>Use CUE modules and provide the following CUE schemas as OCI artifacts.</p> <pre><code>go get k8s.io/api/core/v1\ncue get go k8s.io/api/core/v1\ncue get go k8s.io/apimachinery/pkg/api/resource\ncue get go k8s.io/apimachinery/pkg/apis/meta/v1\ncue get go k8s.io/apimachinery/pkg/runtime\ncue get go k8s.io/apimachinery/pkg/types\ncue get go k8s.io/apimachinery/pkg/watch\ncue get go k8s.io/apimachinery/pkg/util/intstr\nmkdir infrastructure\ntouch infrastructure/prometheus.cue\n</code></pre> <p>Edit <code>infrastructure/prometheus.cue</code> and add:</p> <pre><code>package infrastructure\n\nimport (\n    \"github.com/kharf/navecd/schema/component\"\n    corev1 \"k8s.io/api/core/v1\"\n)\n\n// Public Navecd Manifest Component\nns: component.#Manifest &amp; {\n    content: corev1.#Namespace &amp; {\n        apiVersion: \"v1\"\n        kind:       \"Namespace\"\n        metadata: {\n            name: \"monitoring\"\n        }\n    }\n}\n\n// Public Navecd HelmRelease Component\nprometheusStack: component.#HelmRelease &amp; {\n    dependencies: [\n    // Navecd automatically generates ids for Components, which are used for dependency constraints.\n        ns.id,\n    ]\n    name:      \"prometheus-stack\"\n  // Use namespace name Component reference to reduce redundancy\n    namespace: ns.content.metadata.name\n    chart: {\n        name:    \"kube-prometheus-stack\"\n        repoURL: \"https://prometheus-community.github.io/helm-charts\"\n        version: \"x.x.x\"\n    }\n    values: {\n        prometheus: prometheusSpec: serviceMonitorSelectorNilUsesHelmValues: false\n    }\n}\n</code></pre> <p>See getting-started example.</p> <pre><code>navecd verify\nnavecd push \\\n  -u localhost:5001/mygitops \\\n  -r latest\n</code></pre>"},{"location":"documentation/getting-started/installation/","title":"Installation","text":"<p>Note</p> <p>Currently we don't maintain our binaries in any package manager.</p> <p>You can install Navecd by downloading the binaries directly:</p> Linux (x86_64)MacOS (x86_64)MacOS (arm64) Install script<pre><code>curl -L -o navecd.tar.gz https://github.com/kharf/navecd/releases/download/v0.27.3/navecd_linux_x86_64.tar.gz\ntar -xf navecd.tar.gz\nchmod +x navecd\n./navecd -h\n</code></pre> Install script<pre><code>curl -L -o navecd.tar.gz https://github.com/kharf/navecd/releases/download/v0.27.3/navecd_darwin_x86_64.tar.gz\ntar -xf navecd.tar.gz\nchmod +x navecd\n./navecd -h\n</code></pre> Install script<pre><code>curl -L -o navecd.tar.gz https://github.com/kharf/navecd/releases/download/v0.27.3/navecd_darwin_arm64.tar.gz\ntar -xf navecd.tar.gz\nchmod +x navecd\n./navecd -h\n</code></pre>"}]}